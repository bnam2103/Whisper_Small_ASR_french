{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting datasets==3.6.0\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0.dev20250319+cu128)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.1.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==3.6.0)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.6.0)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets==3.6.0)\n",
      "  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (2.32.3)\n",
      "Collecting tqdm>=4.66.3 (from datasets==3.6.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets==3.6.0)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets==3.6.0)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2024.10.0)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets==3.6.0)\n",
      "  Downloading huggingface_hub-0.35.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.6.0) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting click>=8.1.8 (from jiwer)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.14.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: torch==2.8.0.dev20250319 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch==2.8.0.dev20250319->torchaudio) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch==2.8.0.dev20250319->torchaudio) (77.0.1)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.62.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting scipy>=1.6.0 (from librosa)\n",
      "  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa)\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting joblib>=1.0 (from librosa)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (5.2.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-1.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets==3.6.0)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.45.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2025.1.31)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets==3.6.0)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets==3.6.0)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.8.0.dev20250319->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.8.0.dev20250319->torchaudio) (2.1.5)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m214.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.3/563.3 kB\u001b[0m \u001b[31m139.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (429 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading numba-0.62.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m217.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m177.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.14.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m284.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.0/799.0 kB\u001b[0m \u001b[31m210.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m281.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m181.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m280.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-1.0.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (242 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m312.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m194.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m240.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.45.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m141.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, threadpoolctl, soxr, scipy, safetensors, regex, rapidfuzz, pyarrow, propcache, multidict, msgpack, llvmlite, lazy_loader, joblib, hf-xet, frozenlist, dill, click, audioread, aiohappyeyeballs, yarl, soundfile, scikit-learn, pooch, pandas, numba, multiprocess, jiwer, huggingface-hub, aiosignal, tokenizers, librosa, aiohttp, transformers, datasets, evaluate\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 audioread-3.0.1 click-8.3.0 datasets-3.6.0 dill-0.3.8 evaluate-0.4.6 frozenlist-1.7.0 hf-xet-1.1.10 huggingface-hub-0.35.1 jiwer-4.0.0 joblib-1.5.2 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.45.0 msgpack-1.1.1 multidict-6.6.4 multiprocess-0.70.16 numba-0.62.0 pandas-2.3.2 pooch-1.8.2 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 rapidfuzz-3.14.1 regex-2025.9.18 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.2 soundfile-0.13.1 soxr-1.0.0 threadpoolctl-3.6.0 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.56.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets==3.6.0 evaluate jiwer torchaudio librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# from datasets import Dataset\n",
    "# df = pd.read_csv(\"test.tsv\", sep='\\t')\n",
    "# df = df[['path','sentence']]\n",
    "\n",
    "# # Define the folder containing your audio files\n",
    "# audio_folder = \"test_audio\"\n",
    "\n",
    "# # List all files in the folder\n",
    "# audio_files = set(os.listdir(audio_folder))\n",
    "\n",
    "# # Filter the DataFrame to include only rows where the 'path' exists in the folder\n",
    "# df_filtered = df[df['path'].isin(audio_files)]\n",
    "\n",
    "# # Optionally, save the filtered DataFrame\n",
    "# df_filtered.to_csv(\"filtered_dataframe.csv\", index=False)\n",
    "# df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_pandas(df_filtered)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219ae5526b16419085633b77dfbf9975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43d39b3c10946929af18b90c97aadd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "common_voice_17_0.py:   0%|          | 0.00/8.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cadd8545a3d4cefb83a612e4e80a72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "languages.py:   0%|          | 0.00/3.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a932a222124e5db2476b1809fa761e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "release_stats.py:   0%|          | 0.00/132k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for mozilla-foundation/common_voice_17_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_17_0.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86792b6a0d084a6fb420cfe2f82909a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "n_shards.json:   0%|          | 0.00/17.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cffda893ee44ba95a1985fce68c088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_0.tar:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b03411c5d743ed97e44cfc9d073a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_1.tar:   0%|          | 0.00/1.57G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284307a0aa1a4aa08249c21a15d4b60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_2.tar:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9f107924de4c08a778f5367441753e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_3.tar:   0%|          | 0.00/1.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a028781257f40339bdfc9579180c5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_4.tar:   0%|          | 0.00/1.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d674c59e194479946ff91b06c30e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_5.tar:   0%|          | 0.00/1.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9856db80b4924d36aac4b4c49ffac8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_6.tar:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d9a0ee8a8e407d883ded933cd60fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_7.tar:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f217c92ad049ebb0c40757bf6e34c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_8.tar:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777553c9ad66465bb5087c7448f39f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_9.tar:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde99a6910a94ebd8e70a8eb583c0ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_10.tar:   0%|          | 0.00/1.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b07a46a0a5449e9aa82d548e7b029d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_11.tar:   0%|          | 0.00/1.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abc20a7db2c4fec98fe0aa570ab3f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_12.tar:   0%|          | 0.00/1.60G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b2081936654aedbf609cb2aac94d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/train/fr_train_13.tar:   0%|          | 0.00/1.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d1657de2114e6fa7a0403f50540763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/dev/fr_dev_0.tar:   0%|          | 0.00/706M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52f9c59e8a14f8f84fbab66d84918c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/test/fr_test_0.tar:   0%|          | 0.00/687M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fe7ad2c9b548adabe1fa8f37a8f527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/other/fr_other_0.tar:   0%|          | 0.00/1.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc60e529696843b4ac15f95aa51722a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/invalidated/fr_invalidated_0.ta(…):   0%|          | 0.00/1.80G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46932454c51a406ea9ddddc64b8d97e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/invalidated/fr_invalidated_1.ta(…):   0%|          | 0.00/877M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddb6a589ee74f3689890ab15f097aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/19 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa898f2d1221460ba2977c492d27f62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_2.tar:   0%|          | 0.00/1.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e4e991ab83430080cd38ffd5ea3984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_3.tar:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72d6d17df664e2f87e86aed4abc5fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_0.tar:   0%|          | 0.00/1.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2855e98fdf2f4560a6a221ccbc3bbf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_6.tar:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986f4b601bc74f2d8184c7654a718f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_7.tar:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be993c0b66342a1bc5e02e6dba36428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_1.tar:   0%|          | 0.00/1.53G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8693246c8a9542988f6bbc14c86b0eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_5.tar:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0621d5f9973247ccac8a0f2519571d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_12.tar:   0%|          | 0.00/1.41G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7842d46faae74497a042fc638ed4aa3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_13.tar:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bfa58c0a924667b9b178a1a9f59e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_4.tar:   0%|          | 0.00/1.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda978133bbc4ffa93616f3016af7844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_15.tar:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb17c06169314361a7cf58efdcf8befb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_8.tar:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aecac540e584098aab321ad9b906836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_10.tar:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4989cf7b6d4ee2b50fa0748bf21dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_11.tar:   0%|          | 0.00/1.41G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f949e6eb47c84f399472f557aa087df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_9.tar:   0%|          | 0.00/1.41G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf02d38afed84f0db8f95244bce008a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_14.tar:   0%|          | 0.00/1.37G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae559c765184f028c27e977159d904f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_16.tar:   0%|          | 0.00/1.53G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0042a8162446d6bcc7f200bc7977eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_17.tar:   0%|          | 0.00/1.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efdf8c16e34460aa18c5bfb1e4c6300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "audio/fr/validated/fr_validated_18.tar:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c5d5ea3e134794b171fa71330dfb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transcript/fr/train.tsv:   0%|          | 0.00/184M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1c149b2e284f01a2d1c3375a05ce65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev.tsv:   0%|          | 0.00/4.95M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3d9624d257469bb9203a05c6a0c94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.tsv:   0%|          | 0.00/4.95M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b79764ebe5c46cc8a1278d4470a9f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "other.tsv:   0%|          | 0.00/10.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ed808157654a4ebcc02405ad16745c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transcript/fr/invalidated.tsv:   0%|          | 0.00/20.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f507568095f348c8b54a87ff54754832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transcript/fr/validated.tsv:   0%|          | 0.00/237M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fffb93647ae4d8bb9b394ea28e39fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 13051it [00:00, 130499.86it/s]\u001b[A\n",
      "Reading metadata...: 26628it [00:00, 133591.11it/s]\u001b[A\n",
      "Reading metadata...: 40218it [00:00, 134643.50it/s]\u001b[A\n",
      "Reading metadata...: 53683it [00:00, 134433.92it/s]\u001b[A\n",
      "Reading metadata...: 67208it [00:00, 134726.21it/s]\u001b[A\n",
      "Reading metadata...: 80681it [00:00, 133272.15it/s]\u001b[A\n",
      "Reading metadata...: 94012it [00:00, 131294.83it/s]\u001b[A\n",
      "Reading metadata...: 107148it [00:00, 130318.89it/s]\u001b[A\n",
      "Reading metadata...: 120185it [00:00, 129680.34it/s]\u001b[A\n",
      "Reading metadata...: 133156it [00:01, 128636.03it/s]\u001b[A\n",
      "Reading metadata...: 146022it [00:01, 127144.06it/s]\u001b[A\n",
      "Reading metadata...: 158904it [00:01, 127642.39it/s]\u001b[A\n",
      "Reading metadata...: 171719it [00:01, 127790.59it/s]\u001b[A\n",
      "Reading metadata...: 184501it [00:01, 126581.38it/s]\u001b[A\n",
      "Reading metadata...: 197473it [00:01, 127513.61it/s]\u001b[A\n",
      "Reading metadata...: 210470it [00:01, 128244.23it/s]\u001b[A\n",
      "Reading metadata...: 223476it [00:01, 128783.95it/s]\u001b[A\n",
      "Reading metadata...: 236357it [00:01, 128781.95it/s]\u001b[A\n",
      "Reading metadata...: 249373it [00:01, 129193.42it/s]\u001b[A\n",
      "Reading metadata...: 262294it [00:02, 128686.69it/s]\u001b[A\n",
      "Reading metadata...: 275164it [00:02, 128078.90it/s]\u001b[A\n",
      "Reading metadata...: 287974it [00:02, 127999.23it/s]\u001b[A\n",
      "Reading metadata...: 300775it [00:02, 127366.86it/s]\u001b[A\n",
      "Reading metadata...: 313513it [00:02, 126845.09it/s]\u001b[A\n",
      "Reading metadata...: 326199it [00:02, 126610.25it/s]\u001b[A\n",
      "Reading metadata...: 338861it [00:02, 125700.63it/s]\u001b[A\n",
      "Reading metadata...: 351433it [00:02, 121321.37it/s]\u001b[A\n",
      "Reading metadata...: 364260it [00:02, 123338.31it/s]\u001b[A\n",
      "Reading metadata...: 376989it [00:02, 124493.53it/s]\u001b[A\n",
      "Reading metadata...: 390069it [00:03, 126346.61it/s]\u001b[A\n",
      "Reading metadata...: 402723it [00:03, 126085.72it/s]\u001b[A\n",
      "Reading metadata...: 415345it [00:03, 125888.69it/s]\u001b[A\n",
      "Reading metadata...: 428403it [00:03, 127281.61it/s]\u001b[A\n",
      "Reading metadata...: 441139it [00:03, 127273.80it/s]\u001b[A\n",
      "Reading metadata...: 453950it [00:03, 127521.85it/s]\u001b[A\n",
      "Reading metadata...: 466706it [00:03, 126483.66it/s]\u001b[A\n",
      "Reading metadata...: 480054it [00:03, 128563.77it/s]\u001b[A\n",
      "Reading metadata...: 495061it [00:03, 134977.12it/s]\u001b[A\n",
      "Reading metadata...: 509970it [00:03, 139193.28it/s]\u001b[A\n",
      "Reading metadata...: 525109it [00:04, 142839.97it/s]\u001b[A\n",
      "Reading metadata...: 540369it [00:04, 145760.54it/s]\u001b[A\n",
      "Reading metadata...: 558054it [00:04, 130814.96it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc89803854d342718fa04b1b1ee0ce9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 16159it [00:00, 121497.42it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c62c289f97405eaafddb9d11e7aeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 16159it [00:00, 176904.32it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d263f4af7c6b4056baa01bf06762f690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating other split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 12670it [00:00, 126688.64it/s]\u001b[A\n",
      "Reading metadata...: 32469it [00:00, 134464.92it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8436210679974c6bac3dd1f6d4b8939c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating invalidated split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 13524it [00:00, 135226.91it/s]\u001b[A\n",
      "Reading metadata...: 28449it [00:00, 143469.50it/s]\u001b[A\n",
      "Reading metadata...: 43467it [00:00, 146530.08it/s]\u001b[A\n",
      "Reading metadata...: 63835it [00:00, 144317.31it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e182b96c3545b083e1bf5ead766e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validated split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 18069it [00:00, 180680.26it/s]\u001b[A\n",
      "Reading metadata...: 36138it [00:00, 177741.95it/s]\u001b[A\n",
      "Reading metadata...: 53916it [00:00, 176312.16it/s]\u001b[A\n",
      "Reading metadata...: 71693it [00:00, 176875.87it/s]\u001b[A\n",
      "Reading metadata...: 89383it [00:00, 173389.63it/s]\u001b[A\n",
      "Reading metadata...: 106733it [00:00, 167431.77it/s]\u001b[A\n",
      "Reading metadata...: 123512it [00:00, 152795.53it/s]\u001b[A\n",
      "Reading metadata...: 139006it [00:00, 153322.50it/s]\u001b[A\n",
      "Reading metadata...: 154489it [00:00, 153208.62it/s]\u001b[A\n",
      "Reading metadata...: 169913it [00:01, 153397.99it/s]\u001b[A\n",
      "Reading metadata...: 185325it [00:01, 149601.01it/s]\u001b[A\n",
      "Reading metadata...: 200346it [00:01, 148468.45it/s]\u001b[A\n",
      "Reading metadata...: 215233it [00:01, 148466.05it/s]\u001b[A\n",
      "Reading metadata...: 230160it [00:01, 148700.54it/s]\u001b[A\n",
      "Reading metadata...: 245203it [00:01, 149208.79it/s]\u001b[A\n",
      "Reading metadata...: 260139it [00:01, 149212.85it/s]\u001b[A\n",
      "Reading metadata...: 275071it [00:01, 149182.92it/s]\u001b[A\n",
      "Reading metadata...: 289997it [00:01, 147438.21it/s]\u001b[A\n",
      "Reading metadata...: 304750it [00:01, 146957.30it/s]\u001b[A\n",
      "Reading metadata...: 319452it [00:02, 143491.14it/s]\u001b[A\n",
      "Reading metadata...: 333820it [00:02, 141394.67it/s]\u001b[A\n",
      "Reading metadata...: 347975it [00:02, 141414.84it/s]\u001b[A\n",
      "Reading metadata...: 362128it [00:02, 137022.61it/s]\u001b[A\n",
      "Reading metadata...: 376356it [00:02, 138540.84it/s]\u001b[A\n",
      "Reading metadata...: 390237it [00:02, 138064.95it/s]\u001b[A\n",
      "Reading metadata...: 404062it [00:02, 135668.65it/s]\u001b[A\n",
      "Reading metadata...: 417678it [00:02, 135806.36it/s]\u001b[A\n",
      "Reading metadata...: 431272it [00:02, 135643.76it/s]\u001b[A\n",
      "Reading metadata...: 445152it [00:03, 136573.85it/s]\u001b[A\n",
      "Reading metadata...: 458817it [00:03, 134558.17it/s]\u001b[A\n",
      "Reading metadata...: 473559it [00:03, 138344.58it/s]\u001b[A\n",
      "Reading metadata...: 487408it [00:03, 138042.41it/s]\u001b[A\n",
      "Reading metadata...: 502088it [00:03, 140637.71it/s]\u001b[A\n",
      "Reading metadata...: 516372it [00:03, 141290.67it/s]\u001b[A\n",
      "Reading metadata...: 530935it [00:03, 142582.63it/s]\u001b[A\n",
      "Reading metadata...: 545493it [00:03, 143474.62it/s]\u001b[A\n",
      "Reading metadata...: 559845it [00:03, 142128.91it/s]\u001b[A\n",
      "Reading metadata...: 574817it [00:03, 144382.95it/s]\u001b[A\n",
      "Reading metadata...: 589803it [00:04, 146013.01it/s]\u001b[A\n",
      "Reading metadata...: 604412it [00:04, 146032.21it/s]\u001b[A\n",
      "Reading metadata...: 619019it [00:04, 145896.22it/s]\u001b[A\n",
      "Reading metadata...: 633612it [00:04, 132142.09it/s]\u001b[A\n",
      "Reading metadata...: 647074it [00:04, 123462.56it/s]\u001b[A\n",
      "Reading metadata...: 659673it [00:04, 115839.24it/s]\u001b[A\n",
      "Reading metadata...: 671480it [00:04, 115076.10it/s]\u001b[A\n",
      "Reading metadata...: 683508it [00:04, 116489.33it/s]\u001b[A\n",
      "Reading metadata...: 695675it [00:04, 117936.91it/s]\u001b[A\n",
      "Reading metadata...: 707562it [00:05, 109072.65it/s]\u001b[A\n",
      "Reading metadata...: 726005it [00:05, 139975.55it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "cv_17 = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"fr\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'sentence'],\n",
       "    num_rows: 16159\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = cv_17.remove_columns(['path','client_id','up_votes','down_votes','age','gender','accent','locale','segment','variant'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52319e586ace4e3a8fe9c0092543fa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate: 48000\n",
      "array:[ 0.00000000e+00 -4.95903318e-12 -4.28973263e-13 ... -5.87302275e-05\n",
      " -8.39358181e-05 -7.38822855e-05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'sentence'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = dataset.select(range(1))\n",
    "def print_first_audio(batch): \n",
    "    first_audio = batch[\"audio\"][0] \n",
    "    print(f\"Sampling rate: {first_audio['sampling_rate']}\")\n",
    "    print(f\"array:{first_audio['array']}\")\n",
    "    return batch\n",
    "filtered_data.map(print_first_audio, batched=True, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea1c85c7cdd474e9c4eb901d227fb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate: 16000\n",
      "array:[ 1.45519152e-10 -5.82076609e-11 -5.82076609e-11 ... -2.84506677e-05\n",
      "  2.98366213e-05 -6.71380258e-05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'sentence'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = dataset.select(range(1))\n",
    "def print_first_audio(batch): \n",
    "    first_audio = batch[\"audio\"][0] \n",
    "    print(f\"Sampling rate: {first_audio['sampling_rate']}\")\n",
    "    print(f\"array:{first_audio['array']}\")\n",
    "    return batch\n",
    "filtered_data.map(print_first_audio, batched=True, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_data = dataset.select(range(5))\n",
    "\n",
    "# from datasets import Audio\n",
    "\n",
    "# filtered_data = filtered_data.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a7ebbb8b974a8883f2472ef15304a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16159 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"bofenghuang/whisper-small-cv11-french\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"sentence\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: Ce dernier a évolué tout au long de l'histoire romaine.\n",
      "Transcription: Ce dernier évolue tout au long de l'histoire romaine.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Son actionnaire majoritaire est le Conseil territorial de Saint-Pierre-et-Miquelon.\n",
      "Transcription: Son actionnaire majoritaire est le conseil territorial de Saint-Pierre-et-Miquelon.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Ce site contient quatre tombeaux de la dynastie achéménide et sept des Sassanides.\n",
      "Transcription: Ce site contient quatre tombeaux de la dynastie Hachéménide et sept des Sassanides.\n",
      "--------------------------------------------------\n",
      "Ground Truth: J'ai dit que les acteurs de bois avaient, selon moi, beaucoup d'avantages sur les autres.\n",
      "Transcription: J'ai dit que les acteurs de bois avaient, selon moi, beaucoup d'avantage sur les autres.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Les Pays-Bas ont remporté toutes les éditions.\n",
      "Transcription: Le pays ban reportait toutes les éditions.\n",
      "--------------------------------------------------\n",
      "\n",
      "Average WER: 0.16475284093838383\n",
      "Average CER: 0.06157567302260517\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['sentence']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41b87906b7244f9885958acbbc2bf5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16159 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"nambn0321/ASR_french_3\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"sentence\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size\n",
    "\n",
    "# Now transcribed_dataset contains: 'audio', 'sentence', 'transcription'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: Ce dernier a évolué tout au long de l'histoire romaine.\n",
      "Transcription: Ce dernier est volé tout au long de l'histoire romaine.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Son actionnaire majoritaire est le Conseil territorial de Saint-Pierre-et-Miquelon.\n",
      "Transcription: Son actionnaire majoritaire est le conseil territorial de Saint-Pierre-et-Miculon.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Ce site contient quatre tombeaux de la dynastie achéménide et sept des Sassanides.\n",
      "Transcription: Ce site contient quatre tombeaux de la dynastie Hachéménide et sept des Sassanides.\n",
      "--------------------------------------------------\n",
      "Ground Truth: J'ai dit que les acteurs de bois avaient, selon moi, beaucoup d'avantages sur les autres.\n",
      "Transcription: J’ai dit que les acteurs de bois avaient, selon moi, beaucoup d’avantages sur les autres.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Les Pays-Bas ont remporté toutes les éditions.\n",
      "Transcription: Le Pays-Bas remportait toutes les éditions.\n",
      "--------------------------------------------------\n",
      "\n",
      "Average WER: 0.16480168199411116\n",
      "Average CER: 0.0675692580022672\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['sentence']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61c0f92ee3044c6a09939df9c37f517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810474cbfed640428fb81b910f388974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a74099add41448a8686e5bae7722a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e767c00af9274b598dd04df286cb4958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f082c7d6f5446d8e86ce229077a680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ef71a6373c4f999cd595b648a0aa82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e790cbb0ee245efbc519b53b4016a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d183f2d88a426987df6d38c822460b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775e18af724c441abd4a9a6fc1422846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc896f3061344e08e7863f9f61dc8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7c02e738e84d3b9ac4230a3c90e40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c78ba27199445c896daa552b3fa314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16159 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-medium\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"sentence\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size\n",
    "\n",
    "# Now transcribed_dataset contains: 'audio', 'sentence', 'transcription'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: Ce dernier a évolué tout au long de l'histoire romaine.\n",
      "Transcription:  Ce dernier a évolué tout au long de l'histoire romaine.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Son actionnaire majoritaire est le Conseil territorial de Saint-Pierre-et-Miquelon.\n",
      "Transcription:  Son actionnaire majoritaire est le conseil territoriale de Saint-Pierre-et-Miquelon.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Ce site contient quatre tombeaux de la dynastie achéménide et sept des Sassanides.\n",
      "Transcription:  Ce site contient quatre tombeaux de la dynastie Hasheménide et sept de Sassanide.\n",
      "--------------------------------------------------\n",
      "Ground Truth: J'ai dit que les acteurs de bois avaient, selon moi, beaucoup d'avantages sur les autres.\n",
      "Transcription:  J'ai dit que les acteurs de bois avaient, selon moi, beaucoup d'avantages sur les autres.\n",
      "--------------------------------------------------\n",
      "Ground Truth: Les Pays-Bas ont remporté toutes les éditions.\n",
      "Transcription:  Le pay-back reportait toutes les éditions.\n",
      "--------------------------------------------------\n",
      "\n",
      "Average WER: 0.25968430573168166\n",
      "Average CER: 0.12637983449377893\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['sentence']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93280136ef254373b6e0fbf461cc554d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset 'mozilla-foundation/common_voice_16_0' is a gated dataset on the Hub. Visit the dataset page at https://huggingface.co/datasets/mozilla-foundation/common_voice_16_0 to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDatasetNotFoundError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[32m      3\u001b[39m notebook_login()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m cv_16 = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmozilla-foundation/common_voice_16_0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:2062\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2057\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   2058\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   2059\u001b[39m )\n\u001b[32m   2061\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2062\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2075\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2076\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   2080\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:1782\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[39m\n\u001b[32m   1780\u001b[39m     download_config = download_config.copy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[32m   1781\u001b[39m     download_config.storage_options.update(storage_options)\n\u001b[32m-> \u001b[39m\u001b[32m1782\u001b[39m dataset_module = \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[32m   1795\u001b[39m builder_kwargs = dataset_module.builder_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:1652\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[39m\n\u001b[32m   1650\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (DataFilesNotFoundError, DatasetNotFoundError, EmptyDatasetError)):\n\u001b[32m-> \u001b[39m\u001b[32m1652\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:1636\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[39m\n\u001b[32m   1634\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m e.response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m   1635\u001b[39m         message += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Visit the dataset page at https://huggingface.co/datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to ask for access.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1636\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1637\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1638\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[32m   1639\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRevision \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt exist for dataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m on the Hub.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1640\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mDatasetNotFoundError\u001b[39m: Dataset 'mozilla-foundation/common_voice_16_0' is a gated dataset on the Hub. Visit the dataset page at https://huggingface.co/datasets/mozilla-foundation/common_voice_16_0 to ask for access."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "cv_16 = load_dataset(\"mozilla-foundation/common_voice_16_0\", \"fr\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset = \u001b[43mcv_16\u001b[49m.remove_columns([\u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mclient_id\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mup_votes\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mdown_votes\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mgender\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33maccent\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mlocale\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33msegment\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mvariant\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      2\u001b[39m dataset\n",
      "\u001b[31mNameError\u001b[39m: name 'cv_16' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = cv_16.remove_columns(['path','client_id','up_votes','down_votes','age','gender','accent','locale','segment','variant'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"sentence\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['sentence']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Audio Path: {transcription['audio_path']}\")\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e12941ce884e31ac9f28c76ef4111c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset 'mozilla-foundation/common_voice_15_0' is a gated dataset on the Hub. Visit the dataset page at https://huggingface.co/datasets/mozilla-foundation/common_voice_15_0 to ask for access.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDatasetNotFoundError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[32m      3\u001b[39m notebook_login()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m cv_15 = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmozilla-foundation/common_voice_15_0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:2062\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2057\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   2058\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   2059\u001b[39m )\n\u001b[32m   2061\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2062\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2075\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2076\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   2080\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:1782\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[39m\n\u001b[32m   1780\u001b[39m     download_config = download_config.copy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[32m   1781\u001b[39m     download_config.storage_options.update(storage_options)\n\u001b[32m-> \u001b[39m\u001b[32m1782\u001b[39m dataset_module = \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[32m   1795\u001b[39m builder_kwargs = dataset_module.builder_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:1652\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[39m\n\u001b[32m   1650\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (DataFilesNotFoundError, DatasetNotFoundError, EmptyDatasetError)):\n\u001b[32m-> \u001b[39m\u001b[32m1652\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/datasets/load.py:1636\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[39m\n\u001b[32m   1634\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m e.response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m   1635\u001b[39m         message += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Visit the dataset page at https://huggingface.co/datasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to ask for access.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1636\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1637\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1638\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[32m   1639\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRevision \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt exist for dataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m on the Hub.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1640\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mDatasetNotFoundError\u001b[39m: Dataset 'mozilla-foundation/common_voice_15_0' is a gated dataset on the Hub. Visit the dataset page at https://huggingface.co/datasets/mozilla-foundation/common_voice_15_0 to ask for access."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "cv_15 = load_dataset(\"mozilla-foundation/common_voice_15_0\", \"fr\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cv_15.remove_columns(['path','client_id','up_votes','down_votes','age','gender','accent','locale','segment','variant'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"sentence\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['sentence']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Audio Path: {transcription['audio_path']}\")\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f7965818544c838f08656eea15bcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d052a5c9e334c348671717bff1aca03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecefcd879654457b2a3768bf2878e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38283f9f56d842a0b42508f6e3b97942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/dev-00000-of-00001.parquet:   0%|          | 0.00/157M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0ef01e789f4d5e97c7ac8028a61a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/test-00000-of-00001.parquet:   0%|          | 0.00/158M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8a40f3155448c380620129b0851aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/34 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5789eb62c224e47aec5f857c4a9a292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00000-of-00034.parquet:   0%|          | 0.00/493M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407c5ba312cd464889c7b89600fdd3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00001-of-00034.parquet:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac2ba5fc5184bfe9d098f8485b96ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00002-of-00034.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa030d992dd44718c7f67849c070bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00003-of-00034.parquet:   0%|          | 0.00/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48255a660f83475d8284c8698f9d1342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00004-of-00034.parquet:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7690c40b08944dcaa111ec507d06c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00005-of-00034.parquet:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fc8267caec42ffbf7aa0a9de7d6ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00006-of-00034.parquet:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14036faab3f430e997c2db8b5e812c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00007-of-00034.parquet:   0%|          | 0.00/495M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580089542f19424d9943635d6e1f3f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00008-of-00034.parquet:   0%|          | 0.00/494M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965ccdcaf6c34512bff400d27fd8aa00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00009-of-00034.parquet:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a71c3785a7453aad089240cb87cbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00010-of-00034.parquet:   0%|          | 0.00/487M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f19dfac0934bc0b16596927ec31bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00011-of-00034.parquet:   0%|          | 0.00/494M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcbf4ecd2674ba2aae149b4a976e6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00012-of-00034.parquet:   0%|          | 0.00/489M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a15b5270bf449496f17472d77f3c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00013-of-00034.parquet:   0%|          | 0.00/494M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158c50a9f09244379f420dd8282b5cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00014-of-00034.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3b3a362d2c40c7af06ebd8ed643019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00015-of-00034.parquet:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e28063dd1fe47c6a9618aa3da8a2837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00016-of-00034.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30355e666b43cbafd99010ec467aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00017-of-00034.parquet:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e47ba57a03457792e037fab72f6879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00018-of-00034.parquet:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55db165f26db431c93a8a87e03d96adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00019-of-00034.parquet:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88341b2caab94f23bcd42e84216da3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00020-of-00034.parquet:   0%|          | 0.00/490M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28fa44ad77a4211926cc13f0266ebf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00021-of-00034.parquet:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91efd44fcf28408eb5496c5dacc3d24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00022-of-00034.parquet:   0%|          | 0.00/491M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7a124ace1a42628f2a6b902ec67f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00023-of-00034.parquet:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974bf4b4a12b48deba2ec53cf6bec990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00024-of-00034.parquet:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a800eea356e433eb5fb8621a271edad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00025-of-00034.parquet:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112553f0ff564864a03d5a67471b5254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00026-of-00034.parquet:   0%|          | 0.00/502M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845f506393784526a81bbb0060db5297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00027-of-00034.parquet:   0%|          | 0.00/506M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bed5ccda444b0da940d3bd7aa98ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00028-of-00034.parquet:   0%|          | 0.00/497M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9415fd2c4145454d8b972f188ad9b1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00029-of-00034.parquet:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ca96d9979049939324fa0b00e9dafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00030-of-00034.parquet:   0%|          | 0.00/500M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb921d4686a04d049af650fb5dba98bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00031-of-00034.parquet:   0%|          | 0.00/505M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c54e2f5ef4741aeba61c80ac1392914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00032-of-00034.parquet:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feddafad7981446dba56b2773a149d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/train-00033-of-00034.parquet:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e6088353c84ad8bb831ecfbe707da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/9_hours-00000-of-00001.parquet:   0%|          | 0.00/142M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c6e4e34c5149a5be5b1a52ba6434e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french/1_hours-00000-of-00001.parquet:   0%|          | 0.00/15.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9178165d901d4257990d4806b2e6f2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/2416 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efbb02fa03e4b75b437131be2647b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d8b736fc14438ea2a1feb8b4e1ea70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/258213 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5d3f2cd87b4dcdb12f03f46ad41b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 9_hours split:   0%|          | 0/2167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88f4beb5aab46baa75cc77d93e0229a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating 1_hours split:   0%|          | 0/241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'original_path', 'begin_time', 'end_time', 'transcript', 'audio_duration', 'speaker_id', 'chapter_id', 'file', 'id'],\n",
       "    num_rows: 2426\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Try loading the dataset without streaming\n",
    "dataset = load_dataset(\"facebook/multilingual_librispeech\", \"french\",split=\"test\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'transcript'],\n",
       "    num_rows: 2426\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns(['original_path', 'begin_time', 'end_time', 'audio_duration', 'chapter_id', 'file', 'id','speaker_id'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c524582db5343dd9dd71d334feb1335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f534c8a56a614547b4bc805922032a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554c36a81863468f8b264fa58997dd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a851569dbd43de8c3563e0cd9fd482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa7dfd24203411993878c2aa0b6a15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750e2c7dcfe54cd3827ba996e7de7795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61204a6a336c42cf9ef053c009c4bcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78c2cb6e2f64cbfad89c12d89cd7b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4a4b1760d444b08df7ec91bd809926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae4c889208e479e8dbb8edfe42b633b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a452c6728dd6499ea0994e8ad7fc578d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570e940f8f744800a96038b8f865ff0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"transcript\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: pendant le second siècle je fis serment d'ouvrir tous les trésors de la terre à quiconque me mettrait en liberté mais je ne fus pas plus heureux dans le troisième je promis de faire puissant monarque mon libérateur d'être toujours près de lui en esprit\n",
      "Transcription:  Pendant le second siècle, je fis serment d'ouvrir tous les trésors de la terre, à qui compte me mettre en liberté. Mais je ne suis pas plus heureux. Dans le troisième, je promis de faire puissant mon arc, mon libérateur, d'être toujours près de lui en esprit.\n",
      "--------------------------------------------------\n",
      "Ground Truth: non ta mort est certaine dit le génie choisis seulement de quelle sorte tu veux que je te fasse mourir le pêcheur le voyant dans la résolution de le tuer en eut une douleur extrême non pas tant pour l'amour de lui qu'à cause de ses trois enfants dont il plaignait la misère où ils allaient être réduits par sa mort\n",
      "Transcription:  — Non, ta mort est certaine, dit le génie. Choisis seulement de quelle sorte tu veux que je te fasse mourir. Le pêcheur, le voyant dans les résolutions de le tuer, enut une douleur extrême, non pas tant pour l'amour de lui qu'à cause de ces trois enfants dont il clénait la misère où ils allaient être réduits par sa mort.\n",
      "--------------------------------------------------\n",
      "Ground Truth: la nuit suivante appela sa soeur quand il en fut temps si vous ne dormez pas ma soeur lui dit-elle je vous prie en attendant le jour qui paraîtra bientôt de continuer le conte du pêcheur\n",
      "Transcription:  Dénarza, de la nuit suivante, a place à sœur quand il en fut temps. « Si vous ne dormez pas à ma sœur, lui dit-elle, je vous prie, en attendant le jour qui paraîtra bientôt, de continuer le compte du pêcheur. »\n",
      "--------------------------------------------------\n",
      "Ground Truth: à l'aspect d'un monstre d'une grandeur si démesurée le pêcheur voulut prendre la fuite mais il se trouva si troublé et si effrayé qu'il ne put marcher salomon\n",
      "Transcription:  À l'aspect d'un monstre d'une grandeur si démesurée, le pêcheur voulu prendre la suite, mais il se trouva si troublé et si effrayé qu'il ne pu marcher.\n",
      "--------------------------------------------------\n",
      "Ground Truth: le sultan qui n'avait pas moins d'envie que dinarzade d'entendre la fin de ce conte différa encore la mort de la sultane fin de la dixième nuit cet enregistrement fait partie du domaine public\n",
      "Transcription:  Le sultan qui n'avait pas moins d'envie que Dinarzad d'entendre la fin du second diffère à encore la mort de la sultan. Fin de la dixième nuit. Cet enregistrement fait partie du domaine public.\n",
      "--------------------------------------------------\n",
      "\n",
      "Average WER: 0.3271440059480838\n",
      "Average CER: 0.10664896334763845\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['transcript']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cedbe2e2a6343008ffc670e45c68673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232cd213ebca4da59707adabb095a79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54feb5bb715488fa5feafba75c646bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099c591be79b472bad1cbe9141f7e415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5659fd1a9f03473a84d88583cec5b232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca7924a09124f86ab3deba3e46441f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82c4eee70004046b1d884d8fcd4ffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b4edb18c774ebf919a1db618ffb20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f2d93be6c544a4a2a23dd791736381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2e511f37e148df8d20b481a0443294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/356 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679a4274d75846088506567eef24ee13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
      "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"nambn0321/ASR_french_3\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"transcript\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: pendant le second siècle je fis serment d'ouvrir tous les trésors de la terre à quiconque me mettrait en liberté mais je ne fus pas plus heureux dans le troisième je promis de faire puissant monarque mon libérateur d'être toujours près de lui en esprit\n",
      "Transcription: Pendant le second siècle, je fis serment d’ouvrir tous les trésors de la terre à qui compte me mettre en liberté, mais je ne fus pas plus heureux.Dans le troisième, je promis de faire puissant mon arc, mon libérateur, d’être toujours près de lui en esprit.\n",
      "--------------------------------------------------\n",
      "Ground Truth: non ta mort est certaine dit le génie choisis seulement de quelle sorte tu veux que je te fasse mourir le pêcheur le voyant dans la résolution de le tuer en eut une douleur extrême non pas tant pour l'amour de lui qu'à cause de ses trois enfants dont il plaignait la misère où ils allaient être réduits par sa mort\n",
      "Transcription: Non! ta mort est certaine, dit le génie, choisissez seulement de quelle sorte tu veux que je te fasse mourir! Le pêcheur, le voyant dans les résolutions de le tuer, en eut une douleur extrême, non-patent pour l’amour de lui qu’à cause de ses trois enfants dont il plaignait la misère où il allait être réduit par sa mort.\n",
      "--------------------------------------------------\n",
      "Ground Truth: la nuit suivante appela sa soeur quand il en fut temps si vous ne dormez pas ma soeur lui dit-elle je vous prie en attendant le jour qui paraîtra bientôt de continuer le conte du pêcheur\n",
      "Transcription: Denarzade, la nuit suivante, appela sa sœur quand il en fut un. — Si vous ne dormez pas, ma sœur, lui dit-elle, je vous prie, en attendant le jour qui paraîtra bientôt de continuer le compte du pêcheur.\n",
      "--------------------------------------------------\n",
      "Ground Truth: à l'aspect d'un monstre d'une grandeur si démesurée le pêcheur voulut prendre la fuite mais il se trouva si troublé et si effrayé qu'il ne put marcher salomon\n",
      "Transcription: À l'aspect d'un monstre d'une grandeur si démesurée, le pêcheur voulut prendre la suite, mais il se trouva si troublé et si effrayé qu'il ne put marcher. « Salomon!\n",
      "--------------------------------------------------\n",
      "Ground Truth: le sultan qui n'avait pas moins d'envie que dinarzade d'entendre la fin de ce conte différa encore la mort de la sultane fin de la dixième nuit cet enregistrement fait partie du domaine public\n",
      "Transcription: Le sultan qui n'avait pas moins d'envie que Dinarzade n'entende la fin du second différa encore la mort de la sultane.Fin de la dixième nuit, cet enregistrement fait partie du domaine public.\n",
      "--------------------------------------------------\n",
      "\n",
      "Average WER: 0.32688939739581274\n",
      "Average CER: 0.10128288231259075\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['transcript']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f341c1a43d14e2d99bc6a137c6ed8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957f24631a99414e8e9f80dfbfe6c499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/484M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0063b5c9ed3400e831698af72ef5acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/484M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d3b08aba5346d182945c524524411c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe76eb298db43e28b198e0fade15d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58add53861a4e13a143165b74fdc0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bbb330a9f14714b4517d844041c040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc58b5e6268840cfb3223fe65db11866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17204e88984e4328b1d1c0f6863e5bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74cc719435b414a988dcf205787aef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34a6dfbd84b4971834bc3df653255a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"bofenghuang/whisper-small-cv11-french\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"transcript\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: pendant le second siècle je fis serment d'ouvrir tous les trésors de la terre à quiconque me mettrait en liberté mais je ne fus pas plus heureux dans le troisième je promis de faire puissant monarque mon libérateur d'être toujours près de lui en esprit\n",
      "Transcription: Pendant le second siècle, je fis serment d'ouvrir tous les trésors de la Terre, à qui compte mes maîtresses en liberté, mais je ne fus pas plus heureux.Dans le troisième, je promis de faire puissant monarque, mon libérateur, d'être toujours près de lui en esprit.\n",
      "--------------------------------------------------\n",
      "Ground Truth: non ta mort est certaine dit le génie choisis seulement de quelle sorte tu veux que je te fasse mourir le pêcheur le voyant dans la résolution de le tuer en eut une douleur extrême non pas tant pour l'amour de lui qu'à cause de ses trois enfants dont il plaignait la misère où ils allaient être réduits par sa mort\n",
      "Transcription: Non, ta mort est certaine, dit le génie, choisir seulement de quelle sorte tu veux que je te fasse mourir. Le pêcheur, le voyant dans les résolutions de le tuer, en eut une douleur extrême, non pas tant pour l'amour de lui qu'à cause de ces trois enfants dont il pleignait la misère où il allait être réduit par sa mort.\n",
      "--------------------------------------------------\n",
      "Ground Truth: la nuit suivante appela sa soeur quand il en fut temps si vous ne dormez pas ma soeur lui dit-elle je vous prie en attendant le jour qui paraîtra bientôt de continuer le conte du pêcheur\n",
      "Transcription: Denarza, la nuit suivante, appela sa soeur quand il en fut un si vous ne dormez pas, ma soeur, lui dit-elle, je vous prie en attendant le jour qui paraîtra bientôt de continuer le conte du pêcheur.\n",
      "--------------------------------------------------\n",
      "Ground Truth: à l'aspect d'un monstre d'une grandeur si démesurée le pêcheur voulut prendre la fuite mais il se trouva si troublé et si effrayé qu'il ne put marcher salomon\n",
      "Transcription: À l'aspect d'un monstre d'une grandeur si démesurée, le pêcheur voulut prendre la suite, mais il se trouva si troublé et si effrayé qu'il ne put marcher. Salomon !\n",
      "--------------------------------------------------\n",
      "Ground Truth: le sultan qui n'avait pas moins d'envie que dinarzade d'entendre la fin de ce conte différa encore la mort de la sultane fin de la dixième nuit cet enregistrement fait partie du domaine public\n",
      "Transcription: Le sultan qui n'avait pas moins d'envie que Dinarzade n'entendre la fin de seconde différa encore la mort de la sultane. Fin de la dixième nuit, cet enregistrement fait partie du domaine public.\n",
      "--------------------------------------------------\n",
      "\n",
      "Average WER: 0.3019688860980124\n",
      "Average CER: 0.10244471342692016\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['transcript']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992d71865cbf477b8260f7f067e187bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-medium\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"transcript\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcription\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: pendant le second siècle je fis serment d'ouvrir tous les trésors de la terre à quiconque me mettrait en liberté mais je ne fus pas plus heureux dans le troisième je promis de faire puissant monarque mon libérateur d'être toujours près de lui en esprit\n",
      "Transcription:  Pendant le second siècle, je fis serment d'ouvrir tous les trésors de la terre, à quiconque me mettrait en liberté, mais je ne fus pas plus heureux. Dans le troisième, je promis de faire puissant monarque mon libérateur, d'être toujours près de lui en esprit,\n",
      "--------------------------------------------------\n",
      "Ground Truth: non ta mort est certaine dit le génie choisis seulement de quelle sorte tu veux que je te fasse mourir le pêcheur le voyant dans la résolution de le tuer en eut une douleur extrême non pas tant pour l'amour de lui qu'à cause de ses trois enfants dont il plaignait la misère où ils allaient être réduits par sa mort\n",
      "Transcription:  — Non, ta mort est certaine, dit le génie. Choisis seulement de quelle sorte tu veux que je te fasse mourir. Le pêcheur, le voyant dans les résolutions de le tuer, en eut une douleur extrême, non pas tant pour l'amour de lui qu'à cause de ses trois enfants dont il plaignait la misère où ils allaient être réduits par sa mort.\n",
      "--------------------------------------------------\n",
      "Ground Truth: la nuit suivante appela sa soeur quand il en fut temps si vous ne dormez pas ma soeur lui dit-elle je vous prie en attendant le jour qui paraîtra bientôt de continuer le conte du pêcheur\n",
      "Transcription:  Dénarzade, la nuit suivante, appela sa sœur quand il en fut temps. — Si vous ne dormez pas, ma sœur, lui dit-elle, je vous prie, en attendant le jour qui paraîtra bientôt, de continuer le compte du pêcheur.\n",
      "--------------------------------------------------\n",
      "Ground Truth: à l'aspect d'un monstre d'une grandeur si démesurée le pêcheur voulut prendre la fuite mais il se trouva si troublé et si effrayé qu'il ne put marcher salomon\n",
      "Transcription:  A l'aspect d'un monstre d'une grandeur si démesurée, le pêcheur voulu prendre la suite, mais il se trouva si troublé et si effrayé qu'il ne put marcher. Salomon!\n",
      "--------------------------------------------------\n",
      "Ground Truth: le sultan qui n'avait pas moins d'envie que dinarzade d'entendre la fin de ce conte différa encore la mort de la sultane fin de la dixième nuit cet enregistrement fait partie du domaine public\n",
      "Transcription:  Le sultan, qui n'avait pas moins d'envie que Dinarzade d'entendre la fin de ce conte, différa encore la mort de la sultane. Fin de la dixième nuit. Cet enregistrement fait partie du domaine public.\n",
      "--------------------------------------------------\n",
      "\n",
      "Average WER: 0.2974373806147316\n",
      "Average CER: 0.09191643028263588\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['transcript']\n",
    "    predicted_text = transcription['transcription']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d8dfb125a64e118092a05626c53674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec274146a2e4621b3a3c7e2736da97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57d3b94ecad40878a4c42f9329eccca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fleurs.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3646ef4468944da68065b0df59fb06e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/fr_fr/audio/train.tar.gz:   0%|          | 0.00/1.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d26d7b5fc5436988dc4950f3cc0e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/fr_fr/audio/dev.tar.gz:   0%|          | 0.00/143M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6291a6a0402e41179dfd85f1be628db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/fr_fr/audio/test.tar.gz:   0%|          | 0.00/349M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50b73e811554f2d84f432990896a5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.tsv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4a2c9be2d54f33aa93f4a84466a6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev.tsv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe05137ea8d483db9ef3dcd9122d5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.tsv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8e5b0356e64a4f8b80a90a11bcf0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238321d27172436695ecd0181e5aea97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fc02d01a5341de917017684cca471d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
       "    num_rows: 676\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "fleurs = load_dataset(\"google/fleurs\", \"fr_fr\", split=\"test\")\n",
    "fleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'transcription'],\n",
       "    num_rows: 676\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = fleurs.remove_columns(['id', 'num_samples', 'path', 'raw_transcription', 'gender', 'lang_id', 'lang_group_id','language'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858607f5643e4b65969b3cac23dee3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/676 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"transcription\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcriptions\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['transcription']\n",
    "    predicted_text = transcription['transcriptions']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Audio Path: {transcription['audio_path']}\")\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"transcription\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcriptions\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['transcription']\n",
    "    predicted_text = transcription['transcriptions']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Audio Path: {transcription['audio_path']}\")\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"transcription\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcriptions\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['transcription']\n",
    "    predicted_text = transcription['transcriptions']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Audio Path: {transcription['audio_path']}\")\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
    "\n",
    "# Batched function to transcribe a batch of examples\n",
    "def transcribe_batch(batch):\n",
    "    # Extract audio arrays and sampling rates\n",
    "    audio_arrays = batch[\"audio\"]\n",
    "    inputs = [a[\"array\"] for a in audio_arrays]\n",
    "    sentences = batch[\"transcription\"]\n",
    "    # Transcribe using the pipeline\n",
    "    results = pipe(inputs)\n",
    "\n",
    "    # Extract just the text\n",
    "    transcriptions = [r[\"text\"] for r in results]\n",
    "\n",
    "    # Return the transcriptions as a new column\n",
    "    return {\n",
    "        \"transcriptions\": transcriptions\n",
    "    }\n",
    "\n",
    "# Apply the batched function to the dataset\n",
    "transcriptions = dataset.map(transcribe_batch, batched=True, batch_size=8)  # You can tune batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer, cer\n",
    "\n",
    "total_wer = 0\n",
    "total_cer = 0\n",
    "\n",
    "# Store the WER and CER values for averaging later\n",
    "wer_values = []\n",
    "cer_values = []\n",
    "\n",
    "# Now calculate WER and CER for each transcription and store them\n",
    "for transcription in transcriptions:\n",
    "    ground_truth = transcription['transcription']\n",
    "    predicted_text = transcription['transcriptions']\n",
    "    \n",
    "    # Calculate WER and CER for each transcription\n",
    "    word_error_rate = wer(ground_truth, predicted_text)  # Calculate WER\n",
    "    char_error_rate = cer(ground_truth, predicted_text)  # Calculate CER\n",
    "    \n",
    "    # Append the values to lists for later averaging\n",
    "    wer_values.append(word_error_rate)\n",
    "    cer_values.append(char_error_rate)\n",
    "    \n",
    "    # Print the top 5 transcriptions based on WER (or you can choose CER as well)\n",
    "    if len(wer_values) <= 5:\n",
    "        print(f\"Audio Path: {transcription['audio_path']}\")\n",
    "        print(f\"Ground Truth: {ground_truth}\")\n",
    "        print(f\"Transcription: {predicted_text}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Calculate the average WER and CER\n",
    "avg_wer = sum(wer_values) / len(wer_values) if wer_values else 0\n",
    "avg_cer = sum(cer_values) / len(cer_values) if cer_values else 0\n",
    "\n",
    "# Print the average WER and CER\n",
    "print(\"\\nAverage WER:\", avg_wer)\n",
    "print(\"Average CER:\", avg_cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8185261,
     "sourceId": 12935016,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8185275,
     "sourceId": 12935036,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8192341,
     "sourceId": 12945680,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 441073,
     "modelInstanceId": 423552,
     "sourceId": 556973,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
